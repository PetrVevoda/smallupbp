/*
 * Copyright (C) 2014, Petr Vevoda, Martin Sik (http://cgg.mff.cuni.cz/~sik/), 
 * Tomas Davidovic (http://www.davidovic.cz), Iliyan Georgiev (http://www.iliyan.com/), 
 * Jaroslav Krivanek (http://cgg.mff.cuni.cz/~jaroslav/)
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
 * OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * (The above is MIT License: http://en.wikipedia.origin/wiki/MIT_License)
 */

#ifndef __UPBP_HXX__
#define __UPBP_HXX__

#include <vector>
#include <cmath>

#include "..\Beams\PhBeams.hxx"
#include "..\Bre\Bre.hxx"
#include "..\Misc\HashGrid.hxx"
#include "..\Misc\Timer.hxx"
#include "..\Path\PathWeight.hxx"
#include "Renderer.hxx"

#define UPBP_CAMERA_MAXVERTS 1001
#define UPBP_LIGHT_AVGVERTS 20

class UPBP : public AbstractRenderer
{
	// The sole point of this structure is to make carrying around the ray baggage easier.
	struct SubPathState
	{
		Pos   mOrigin;             // Path origin
		Dir   mDirection;          // Where to go next
		Rgb   mThroughput;         // Path throughput           
		uint  mPathLength : 30;    // Number of path segments, including this
		uint  mIsFiniteLight : 1;  // Just generated by finite light
		uint  mSpecularPath : 1;   // All scattering events so far were specular 
		bool  mLastSpecular;       // Last sampled event was specular
		float mLastPdfWInv;        // PDF of the last sampled direction

		BoundaryStack mBoundaryStack; // Stack of crossed boundaries		
	};

	// Range query used for PPM, BPM, and UPBP. When HashGrid finds a vertex
	// within range -- Process() is called and vertex
	// merging is performed. BSDF of the camera vertex is used.
	class RangeQuery
	{
	public:

		RangeQuery(
			const UPBP         &aUPBP,
			const Pos          &aCameraPosition,
			const BSDF         &aCameraBsdf,
			const SubPathState &aCameraState,
			const DebugImages  &aDebugImages
			) :
			mUPBP(aUPBP),
			mCameraPosition(aCameraPosition),
			mCameraBsdf(aCameraBsdf),
			mCameraState(aCameraState),
			mContrib(0),
			mDebugImages(aDebugImages)
		{}

		const Pos& GetPosition() const { return mCameraPosition; }

		const Rgb& GetContrib() const { return mContrib; }

		void Process(const UPBPLightVertex& aLightVertex)
		{
			// We store all light vertices but not all can be used for merging (delta and light)
			if (!aLightVertex.mConnectable)
				return;

			// Use only vertices with same location (on surface/in medium)
			UPBP_ASSERT(aLightVertex.mInMedium == mCameraBsdf.IsInMedium());
			
			// Reject if full path length below/above min/max path length
			if ((aLightVertex.mPathLength + mCameraState.mPathLength > mUPBP.mMaxPathLength) ||
				(aLightVertex.mPathLength + mCameraState.mPathLength < mUPBP.mMinPathLength))
				return;

			// Retrieve light incoming direction in world coordinates
			const Dir lightDirection = aLightVertex.mBSDF.WorldDirFix();

			float cosCamera, cameraBsdfDirPdfW, cameraBsdfRevPdfW, sinTheta;
			const Rgb cameraBsdfFactor = mCameraBsdf.Evaluate(
				lightDirection, cosCamera, &cameraBsdfDirPdfW,
				&cameraBsdfRevPdfW, &sinTheta);

			if (cameraBsdfFactor.isBlackOrNegative())
				return;

			cameraBsdfDirPdfW *= mCameraBsdf.ContinuationProb();
			UPBP_ASSERT(cameraBsdfDirPdfW > 0);

			// Even though this is PDF from camera BSDF, the continuation probability
			// must come from light BSDF, because that would govern it if light path
			// actually continued
			cameraBsdfRevPdfW *= aLightVertex.mBSDF.ContinuationProb();
			UPBP_ASSERT(cameraBsdfRevPdfW > 0);

			// MIS weight
			float misWeight = 1.0f;
			if (mUPBP.mAlgorithm != kPPM)
			{
				const float misWeightFactorInv = 1.0f / (aLightVertex.mInMedium ? aLightVertex.mMisData.mPP3DMisWeightFactor : aLightVertex.mMisData.mSurfMisWeightFactor);
				const float wCamera = mUPBP.AccumulateCameraPathWeight2(mCameraState.mPathLength, misWeightFactorInv, sinTheta, aLightVertex.mMisData.mRaySamplePdfInv, aLightVertex.mMisData.mRaySamplePdfsRatio, cameraBsdfRevPdfW);
				const float wLight = mUPBP.AccumulateLightPathWeight2(aLightVertex.mPathIdx, aLightVertex.mPathLength, misWeightFactorInv, 0, 0, 0, cameraBsdfDirPdfW, aLightVertex.mInMedium ? PP3D : SURF, false);
				misWeight = 1.f / (wLight + wCamera);
			}

			const Rgb mult = cameraBsdfFactor * aLightVertex.mThroughput;
			mContrib += misWeight * mult;
			mDebugImages.accumRgbWeight(aLightVertex.mPathLength, aLightVertex.mInMedium ? DebugImages::PP3D : DebugImages::SURFACE_PHOTON_MAPPING, mult, misWeight);
		}

	private:

		const UPBP         &mUPBP;
		const Pos          &mCameraPosition;
		const BSDF         &mCameraBsdf;
		const SubPathState &mCameraState;
		Rgb                mContrib;
		const DebugImages  &mDebugImages;
	};

public:

	enum AlgorithmType
	{
		kLT = 0,   // light tracing
		kPTdir,    // direct path tracing
		kPTls,     // path tracing with light sampling
		kPTmis,    // path tracing with MIS
		kBPT,      // bidirectional path tracing
		kPPM,      // camera and light vertices merged on first non-specular surface from camera (cannot handle mixed specular + non-specular materials)
		kBPM,      // camera and light vertices merged on along full path
		kVCM,      // vertex connection and merging
		kCustom    // combination of techniques (BPT, SURF, PP3D, PB2D, BB1D) specified using flags
	};

	UPBP(
        const Scene&            aScene,
		const AlgorithmType     aAlgorithm,
		const uint              aEstimatorTechniques,
		const float             aSurfRadiusInitial,
		const float             aSurfRadiusAlpha,
		const float             aPP3DRadiusInitial,
		const float             aPP3DRadiusAlpha,
		const float		        aPB2DRadiusInitial,
		const float             aPB2DRadiusAlpha,
		const RadiusCalculation aPB2DRadiusCalculation,
		const int		        aPB2DRadiusKNN,
		const BeamType          aQueryBeamType,
		const float 	        aBB1DRadiusInitial,
		const float             aBB1DRadiusAlpha,
		const RadiusCalculation aBB1DRadiusCalculation,
		const int		        aBB1DRadiusKNN,
		const BeamType          aPhotonBeamType,
		const float             aBB1DUsedLightSubPathCount,
		const float             aBB1DBeamStorageFactor,
		const float             aRefPathCountPerIter,
		const float             aPathCountPerIter,
		const float             aMinDistToMed,
		const size_t			aMaxMemoryPerThread,
		const int               aSeed = 1234,
		const int               aBaseSeed = 1234,
		const bool				aIgnoreFullySpecPaths = false,
		const bool              aVerbose = false) :
		AbstractRenderer(aScene),
		mPB2DEmbreeBre(aScene),
		mBB1DPhotonBeams(aScene),
		mAlgorithm(aAlgorithm),
		mEstimatorTechniques(aEstimatorTechniques),
		mSurfRadiusInitial(aSurfRadiusInitial),
		mSurfRadiusAlpha(aSurfRadiusAlpha),
		mPP3DRadiusInitial(aPP3DRadiusInitial),
		mPP3DRadiusAlpha(aPP3DRadiusAlpha),		
		mPB2DRadiusInitial(aPB2DRadiusInitial),
		mPB2DRadiusAlpha(aPB2DRadiusAlpha),
		mPB2DRadiusCalculation(aPB2DRadiusCalculation),		
		mPB2DRadiusKNN(aPB2DRadiusKNN),
		mQueryBeamType(aQueryBeamType),
		mBB1DRadiusInitial(aBB1DRadiusInitial),
		mBB1DRadiusAlpha(aBB1DRadiusAlpha),
		mBB1DRadiusCalculation(aBB1DRadiusCalculation),		
		mBB1DRadiusKNN(aBB1DRadiusKNN),
		mPhotonBeamType(aPhotonBeamType),
		mBB1DUsedLightSubPathCount(aBB1DUsedLightSubPathCount),
		mBB1DBeamStorageFactor(aBB1DBeamStorageFactor),
		mRefPathCountPerIter(aRefPathCountPerIter),
		mPathCountPerIter(aPathCountPerIter),
		mMinDistToMed(aMinDistToMed),
		mMaxMemoryPerThread(aMaxMemoryPerThread),
		mIgnoreFullySpecPaths(aIgnoreFullySpecPaths),
		mRng(aSeed),
		mBaseSeed(aBaseSeed),
		mVerbose(aVerbose)
	{				
		if (mSurfRadiusInitial < 0)
			mSurfRadiusInitial = -mSurfRadiusInitial * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mSurfRadiusInitial > 0);

		if (mPP3DRadiusInitial < 0)
			mPP3DRadiusInitial = -mPP3DRadiusInitial * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mPP3DRadiusInitial > 0);

		if (mPB2DRadiusInitial < 0)
			mPB2DRadiusInitial = -mPB2DRadiusInitial * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mPB2DRadiusInitial > 0);

		if (mBB1DRadiusInitial < 0)
			mBB1DRadiusInitial = -mBB1DRadiusInitial * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mBB1DRadiusInitial > 0);

		if (mMinDistToMed < 0)
			mMinDistToMed = -mMinDistToMed * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mMinDistToMed >= 0);

		if (mAlgorithm == kPPM)
		{
			// We will check the scene to make sure it does not contain mixed
			// specular and non-specular materials
			for (int i = 0; i < mScene.GetMaterialCount(); ++i)
			{
				const Material &mat = mScene.GetMaterial(i);

				const bool hasNonSpecular =
					(mat.mDiffuseReflectance.max() > 0) ||
					(mat.mPhongReflectance.max() > 0);

				const bool hasSpecular =
					(mat.mMirrorReflectance.max() > 0) ||
					(mat.mIOR > 0);

				if (hasNonSpecular && hasSpecular)
				{
					printf(
						"*WARNING* Our PPM implementation cannot handle materials mixing\n"
						"Specular and NonSpecular BSDFs. The extension would be\n"
						"fairly straightforward. In SampleScattering for camera sub-paths\n"
						"limit the considered events to Specular only.\n"
						"Merging will use non-specular components, scattering will be specular.\n"
						"If there is no specular component, the ray will terminate.\n\n");

					printf("We are now switching from *PPM* to *BPM*, which can handle the scene\n\n");

					mAlgorithm = kBPM;
					break;
				}
			}
		}

		switch (mAlgorithm)
		{
		case kLT:
			mTraceLightPaths            = true;
			mTraceCameraPaths           = false;
			mConnectToCamera            = true;
			mConnectToLightSource       = false;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = false;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kPTdir:
			mTraceLightPaths            = false;
			mTraceCameraPaths           = true;
			mConnectToCamera            = false;
			mConnectToLightSource       = false;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = false;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kPTls:
			mTraceLightPaths            = false;
			mTraceCameraPaths           = true;
			mConnectToCamera            = false;
			mConnectToLightSource       = true;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = false;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kPTmis:
			mTraceLightPaths            = false;
			mTraceCameraPaths           = true;
			mConnectToCamera            = false;
			mConnectToLightSource       = true;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = false;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kBPT:
			mTraceLightPaths            = true;
			mTraceCameraPaths           = true;
			mConnectToCamera            = true;
			mConnectToLightSource       = true;
			mConnectToLightVertices     = true;
			mMergeWithLightVerticesSurf = false;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kPPM:
			mTraceLightPaths            = true;
			mTraceCameraPaths           = true;
			mConnectToCamera            = false;
			mConnectToLightSource       = false;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = true;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kBPM:
			mTraceLightPaths            = true;
			mTraceCameraPaths           = true;
			mConnectToCamera            = false;
			mConnectToLightSource       = false;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = true;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kVCM:
			mTraceLightPaths            = true;
			mTraceCameraPaths           = true;
			mConnectToCamera            = true;
			mConnectToLightSource       = true;
			mConnectToLightVertices     = true;
			mMergeWithLightVerticesSurf = true;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
			break;
		case kCustom:
			mTraceLightPaths            = mEstimatorTechniques != 0;
			mTraceCameraPaths           = mEstimatorTechniques != 0;
			mConnectToCamera            = mEstimatorTechniques & BPT;
			mConnectToLightSource       = mEstimatorTechniques & BPT;
			mConnectToLightVertices     = mEstimatorTechniques & BPT;
			mMergeWithLightVerticesSurf = mEstimatorTechniques & SURF;
			mMergeWithLightVerticesPP3D = mEstimatorTechniques & PP3D;
			mMergeWithLightVerticesPB2D = mEstimatorTechniques & PB2D;
			mMergeWithLightVerticesBB1D = mEstimatorTechniques & BB1D;
			break;
		}

		mConnectToCameraFromSurf = (mEstimatorTechniques & (PREVIOUS|COMPATIBLE)) == 0;

		if (mAlgorithm != kCustom)
		{
			if (mConnectToLightVertices) mEstimatorTechniques |= BPT;
			if (mMergeWithLightVerticesSurf) mEstimatorTechniques |= SURF;
			if (mMergeWithLightVerticesPP3D) mEstimatorTechniques |= PP3D;
			if (mMergeWithLightVerticesPB2D) mEstimatorTechniques |= PB2D;
			if (mMergeWithLightVerticesBB1D) mEstimatorTechniques |= BB1D;
		}

		if (mEstimatorTechniques & SPECULAR_ONLY)
		{
			mTraceLightPaths            = false;
			mTraceCameraPaths           = true;
			mConnectToCamera            = false;
			mConnectToLightSource       = false;
			mConnectToLightVertices     = false;
			mMergeWithLightVerticesSurf = false;
			mMergeWithLightVerticesPP3D = false;
			mMergeWithLightVerticesPB2D = false;
			mMergeWithLightVerticesBB1D = false;
		}
	}

	virtual void RunIteration(int aIteration)
	{
		// Get path count, one path for each pixel
		const int resX = int(mScene.mCamera.mResolution.get(0));
		const int resY = int(mScene.mCamera.mResolution.get(1));
		int pathCountC = resX * resY;
		int pathCountL = mPathCountPerIter;

		// We don't have the same number of pixels (camera paths)
		// and light paths
		mScreenPixelCount = float(pathCountC);
		mLightSubPathCount = mPathCountPerIter;

		if (!(mEstimatorTechniques & SPECULAR_ONLY))
		{
			// To make list of photons and beams same in previous and compatible mode
			mRng = Rng(mBaseSeed + aIteration);
			mBB1DPhotonBeams.mSeed = mBaseSeed + aIteration;

			if (mBB1DUsedLightSubPathCount < 0)
				mBB1DUsedLightSubPathCount = std::floor(-mBB1DUsedLightSubPathCount * mLightSubPathCount);

			// Radius reduction (1st iteration has aIteration == 0, thus offset)
			const float effectiveIteration = 1 + aIteration * mLightSubPathCount / mRefPathCountPerIter;
			// SURF
			float radiusSurf = mSurfRadiusInitial * std::pow(effectiveIteration, (mSurfRadiusAlpha - 1) * 0.5f);
			radiusSurf = std::max(radiusSurf, 1e-7f); // Purely for numeric stability
			const float radiusSurfSqr = Utils::sqr(radiusSurf);
			// PP3D
			float radiusPP3D = mPP3DRadiusInitial * std::pow(effectiveIteration, (mPP3DRadiusAlpha - 1) * (1.f / 3.f));
			radiusPP3D = std::max(radiusPP3D, 1e-7f); // Purely for numeric stability
			const float radiusPP3DCube = Utils::sqr(radiusPP3D) * radiusPP3D;
			// PB2D
			float radiusPB2D = mPB2DRadiusInitial * std::pow(effectiveIteration, (mPB2DRadiusAlpha - 1) * 0.5f);
			radiusPB2D = std::max(radiusPB2D, 1e-7f); // Purely for numeric stability
			const float radiusPB2DSqr = Utils::sqr(radiusPB2D);
			// BB1D
			float radiusBB1D = mBB1DRadiusInitial * std::pow(1 + aIteration * mBB1DUsedLightSubPathCount / mRefPathCountPerIter, mBB1DRadiusAlpha - 1);
			radiusBB1D = std::max(radiusBB1D, 1e-7f); // Purely for numeric stability

			// Constant for decision whether to store beams or not
			mBB1DMinMFP = mBB1DBeamStorageFactor * 0.5f * PI_F * radiusBB1D;
			if (mVerbose) std::cout << "min mfp: " << mBB1DMinMFP << std::endl;

			const float etaSurf = (PI_F * radiusSurfSqr) * mLightSubPathCount;
			const float etaPP3D = (4.0f / 3.0f) * (PI_F * radiusPP3DCube) * mLightSubPathCount;
			const float etaPB2D = (PI_F * radiusPB2DSqr) * mLightSubPathCount;
			const float etaBB1D = 0.5f * radiusBB1D * mBB1DUsedLightSubPathCount;

			// Factor used to normalize vertex merging contribution.
			// We divide the summed up energy by disk radius and number of light paths
			mSurfNormalization = 1.f / etaSurf;
			mPP3DNormalization = 1.f / etaPP3D;
			mPB2DNormalization = 1.f / mLightSubPathCount;
			mBB1DNormalization = 1.f / mBB1DUsedLightSubPathCount;

			// MIS weight constants
			mSurfMisWeightFactor = etaSurf;
			mPP3DMisWeightFactor = etaPP3D;
			mPB2DMisWeightFactor = etaPB2D;
			mBB1DMisWeightFactor = etaBB1D;

			// Clear path ends, nothing ends anywhere
			mPathEnds.resize(pathCountL);
			memset(&mPathEnds[0], 0, mPathEnds.size() * sizeof(int));

			// Because of static mCameraVerticesMisData size
			UPBP_ASSERT(mMaxPathLength < UPBP_CAMERA_MAXVERTS);

			const float maxLightVerts = std::min(mLightSubPathCount * std::min((int)mMaxPathLength, UPBP_LIGHT_AVGVERTS), (float)mMaxMemoryPerThread / sizeof(UPBPLightVertex));
			const float maxBeams = std::min(mBB1DUsedLightSubPathCount * std::min((int)mMaxPathLength, UPBP_LIGHT_AVGVERTS), (float)mMaxMemoryPerThread / sizeof(UPBPLightVertex));
			
			if (mVerbose)
				std::cout << "allocating : " << ((int)maxLightVerts) << std::endl;
			
			// Remove all light vertices and reserve space for some		
			mLightVertices.clear();
			mLightVertices.reserve((int)maxLightVerts);
			
			if (mVerbose)
				std::cout << "allocating : " << mLightVertices.capacity() << std::endl;
			UPBP_ASSERT(mLightVertices.size() == 0 && mLightVertices.capacity() >= (int)maxLightVerts);

			mPhotonBeamsArray.clear();
			mPhotonBeamsArray.reserve((int)maxBeams);
			UPBP_ASSERT(mPhotonBeamsArray.size() == 0 && mPhotonBeamsArray.capacity() >= (int)maxBeams);

			mLightVerticesOnSurfaceCount = 0;
			mLightVerticesInMediumCount = 0;

			//////////////////////////////////////////////////////////////////////////
			// Generate light paths
			//////////////////////////////////////////////////////////////////////////

			if (mVerbose)
				std::cout << " + tracing light sub-paths..." << std::endl;

			mTimer.Start();

			// If pure path tracing is used, there are no lights or only one path segment is allowed, light tracing step is skipped
			if (mTraceLightPaths && mScene.GetLightCount() > 0 && mMaxPathLength > 1)
			for (int pathIdx = 0; pathIdx < pathCountL; pathIdx++)
			{
				// Generate light path origin and direction
				SubPathState lightState;
				GenerateLightSample(pathIdx, lightState);

				// In attenuating media the ray can never travel from infinity
				if (!lightState.mIsFiniteLight && mScene.GetGlobalMediumPtr()->HasAttenuation())
				{
					mPathEnds[pathIdx] = (int)mLightVertices.size();
					continue;
				}

				// We assume that the light is on surface
				bool originInMedium = false;

				//////////////////////////////////////////////////////////////////////////
				// Trace light path
				for (;; ++lightState.mPathLength)
				{
					// Prepare ray
					Ray ray(lightState.mOrigin, lightState.mDirection);
					Isect isect(1e36f);

					// Trace ray
					mVolumeSegments.clear();
					mLiteVolumeSegments.clear();
					bool intersected = mScene.Intersect(ray, originInMedium ? AbstractMedium::kOriginInMedium : 0, mRng, isect, lightState.mBoundaryStack, mVolumeSegments, mLiteVolumeSegments);

					// Store beam if required
					if (mMergeWithLightVerticesBB1D && pathIdx < mBB1DUsedLightSubPathCount)
					{
						AddBeams(ray, lightState.mThroughput, &mLightVertices.back(), originInMedium ? AbstractMedium::kOriginInMedium : 0, lightState.mLastPdfWInv);
					}

					if (!intersected)
						break;

					UPBP_ASSERT(isect.IsValid());

					// Attenuate by intersected media (if any)
					float raySamplePdf(1.0f);
					float raySampleRevPdf(1.0f);
					if (!mVolumeSegments.empty())
					{
						// PDF
						raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
						UPBP_ASSERT(raySamplePdf > 0);

						// Reverse PDF
						raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
						UPBP_ASSERT(raySampleRevPdf > 0);

						// Attenuation
						lightState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;
					}

					if (lightState.mThroughput.isBlackOrNegative())
						break;

					// Prepare scattering function at the hitpoint (BSDF/phase depending on whether the hitpoint is at surface or in media, the isect knows)
					BSDF bsdf(ray, isect, mScene, BSDF::kFromLight, mScene.RelativeIOR(isect, lightState.mBoundaryStack));

					if (!bsdf.IsValid()) // e.g. hitting surface too parallel with tangent plane
						break;

					// Compute hitpoint
					const Pos hitPoint = ray.origin + ray.direction * isect.mDist;

					originInMedium = isect.IsInMedium();

					// Store vertex
					{
						UPBPLightVertex lightVertex;
						lightVertex.mHitpoint = hitPoint;
						lightVertex.mThroughput = lightState.mThroughput;
						lightVertex.mPathIdx = pathIdx;
						lightVertex.mPathLength = lightState.mPathLength;
						lightVertex.mInMedium = originInMedium;
						lightVertex.mConnectable = !bsdf.IsDelta();
						lightVertex.mIsFinite = true;
						lightVertex.mBSDF = bsdf;

						// Determine whether the vertex is in medium behind real geometry
						lightVertex.mBehindSurf = false;
						if (lightVertex.mInMedium && !lightState.mBoundaryStack.IsEmpty())
						{
							int matId = lightState.mBoundaryStack.Top().mMaterialId;
							if (matId >= 0)
							{
								const Material& mat = mScene.GetMaterial(matId);
								if (mat.mGeometryType != GeometryType::IMAGINARY)
									lightVertex.mBehindSurf = true;
							}
						}

						// Infinite lights use MIS handled via solid angle integration, so do not divide by the distance for such lights
						const float distSq = (lightState.mPathLength > 1 || lightState.mIsFiniteLight == 1) ? Utils::sqr(isect.mDist) : 1.0f;
						const float raySamplePdfInv = 1.0f / raySamplePdf;
						lightVertex.mMisData.mPdfAInv = lightState.mLastPdfWInv * distSq * raySamplePdfInv / std::abs(bsdf.CosThetaFix());
						lightVertex.mMisData.mRevPdfA = 1.0f;
						lightVertex.mMisData.mRevPdfAWithoutBsdf = lightVertex.mMisData.mRevPdfA;
						lightVertex.mMisData.mRaySamplePdfInv = raySamplePdfInv;
						lightVertex.mMisData.mRaySampleRevPdfInv = 1.0f;
						lightVertex.mMisData.mSinTheta = 0.0f;
						lightVertex.mMisData.mSurfMisWeightFactor = bsdf.IsOnSurface() ? mSurfMisWeightFactor : 0;
						lightVertex.mMisData.mPP3DMisWeightFactor = bsdf.IsOnSurface() ? 0 : mPP3DMisWeightFactor;
						lightVertex.mMisData.mPB2DMisWeightFactor = bsdf.IsOnSurface() ? 0 : mPB2DMisWeightFactor;
						lightVertex.mMisData.mBB1DMisWeightFactor = bsdf.IsOnSurface() ? 0 : mBB1DMisWeightFactor;
						lightVertex.mMisData.mBB1DBeamSelectionPdf = bsdf.IsOnSurface() ? 0 : 1;
						lightVertex.mMisData.mIsDelta = bsdf.IsDelta();
						lightVertex.mMisData.mIsOnLightSource = false;
						lightVertex.mMisData.mIsSpecular = false;
						lightVertex.mMisData.mInMediumWithBeams = bsdf.IsOnSurface() ? false : (!mMergeWithLightVerticesPB2D || bsdf.GetMedium()->GetMeanFreePath(hitPoint) > mBB1DMinMFP);

						lightVertex.mMisData.mRaySamplePdfsRatio = 0.0f;
						lightVertex.mMisData.mRaySampleRevPdfsRatio = 0.0f;
						if (bsdf.IsInMedium())
						{
							if (bsdf.GetMedium()->IsHomogeneous())
							{
								lightVertex.mMisData.mRaySamplePdfsRatio = 1.0f / ((const HomogeneousMedium*)bsdf.GetMedium())->mMinPositiveAttenuationCoefCoord();
								lightVertex.mMisData.mRaySampleRevPdfsRatio = lightVertex.mMisData.mRaySamplePdfsRatio;
							}
							else
							{
								const float lastSegmentRayOverSamplePdf = bsdf.GetMedium()->RaySamplePdf(ray, mVolumeSegments.back().mDistMin, mVolumeSegments.back().mDistMax, 0);
								const float lastSegmentRayInSamplePdf = mVolumeSegments.back().mRaySamplePdf; // We are in medium -> we know we have insampled
								lightVertex.mMisData.mRaySamplePdfsRatio = lastSegmentRayOverSamplePdf / lastSegmentRayInSamplePdf;
							}
						}

						// Update reverse PDFs of the previous vertex
						mLightVertices.back().mMisData.mRevPdfA *= raySampleRevPdf / distSq;
						mLightVertices.back().mMisData.mRevPdfAWithoutBsdf = mLightVertices.back().mMisData.mRevPdfA;
						mLightVertices.back().mMisData.mRaySampleRevPdfInv = 1.0f / raySampleRevPdf;

						if (mLightVertices.back().mBSDF.IsInMedium() && !mLightVertices.back().mBSDF.GetMedium()->IsHomogeneous()) // Homogeneous case was solved immediately when processing the vertex for the first time
						{
							float firstSegmentRayOverSampleRevPdf;
							mLightVertices.back().mBSDF.GetMedium()->RaySamplePdf(ray, mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
							const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We were in medium -> we know we have insampled
							mLightVertices.back().mMisData.mRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
						}

						if (lightVertex.mInMedium)
							mLightVerticesInMediumCount++;
						else
							mLightVerticesOnSurfaceCount++;

						UPBP_ASSERT(mLightVertices.size() < mLightVertices.capacity());
						mLightVertices.push_back(lightVertex);
					}

					// Connect to camera, unless scattering function is purely specular or we are not allowed to connect from surface
					if (mConnectToCamera && !bsdf.IsDelta() && (bsdf.IsInMedium() || mConnectToCameraFromSurf))
					{
						if (lightState.mPathLength + 1 >= mMinPathLength)
							ConnectToCamera(pathIdx, lightState, hitPoint, bsdf, mLightVertices.back().mMisData.mRaySamplePdfsRatio);
					}

					// Terminate if the path would become too long after scattering
					if (lightState.mPathLength + 2 > mMaxPathLength)
						break;

					// Continue random walk
					bool passed = false;
					if (!SampleScattering(bsdf, hitPoint, isect, lightState, mLightVertices.back().mMisData, mLightVertices.at(mLightVertices.size() - 2).mMisData))
						break;
				}

				mPathEnds[pathIdx] = (int)mLightVertices.size();
			}

			mTimer.Stop();
			if (mVerbose)
				std::cout << "    - light sub-path tracing done in " << mTimer.GetLastElapsedTime() << " sec. " << std::endl;

			int photons = 0;

			if (mMaxPathLength > 1)
			{
				if (!mLightVertices.empty())
				{
					//////////////////////////////////////////////////////////////////////////
					// Build acceleration structure for SURF
					//////////////////////////////////////////////////////////////////////////
					if (mMergeWithLightVerticesSurf && mLightVerticesOnSurfaceCount)
					{
						// The number of cells is somewhat arbitrary, but seems to work ok
						mSurfHashGrid.Reserve(pathCountL);
						mSurfHashGrid.Build(mLightVertices, radiusSurf, SURF);
					}

					//////////////////////////////////////////////////////////////////////////
					// Build acceleration structure for PP3D
					//////////////////////////////////////////////////////////////////////////
					if (mMergeWithLightVerticesPP3D && mLightVerticesInMediumCount)
					{
						// The number of cells is somewhat arbitrary, but seems to work ok
						mPP3DHashGrid.Reserve(pathCountL);
						mPP3DHashGrid.Build(mLightVertices, radiusPP3D, PP3D);
					}

					//////////////////////////////////////////////////////////////////////////
					// Build acceleration structure for PB2D
					//////////////////////////////////////////////////////////////////////////
					if (mMergeWithLightVerticesPB2D)
					{
						photons = mPB2DEmbreeBre.build(&mLightVertices[0], (int)mLightVertices.size(), mPB2DRadiusCalculation, radiusPB2D, mPB2DRadiusKNN, mVerbose);
					}
				}

				//////////////////////////////////////////////////////////////////////////
				// Build acceleration structure pro BB1D
				//////////////////////////////////////////////////////////////////////////
				if (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty())
				{
					mBB1DPhotonBeams.build(mPhotonBeamsArray, mBB1DRadiusCalculation, radiusBB1D, mBB1DRadiusKNN, mVerbose);

					// Set beam selection PDFs according to the built structure
					if (mBB1DPhotonBeams.sMaxBeamsInCell)
					for (std::vector<UPBPLightVertex>::iterator i = mLightVertices.begin(); i != mLightVertices.end(); ++i)
					{
						if (i->mBSDF.IsInMedium())
							i->mMisData.mBB1DBeamSelectionPdf = mBB1DPhotonBeams.getBeamSelectionPdf(i->mHitpoint);
					}
				}
			}
		}

		//////////////////////////////////////////////////////////////////////////
		// Generate camera paths
		//////////////////////////////////////////////////////////////////////////

		if (mVerbose)
			std::cout << " + tracing camera sub-paths..." << std::endl;
		mTimer.Start();

		// Unless rendering with traditional light tracing
		if (mTraceCameraPaths)
		for (int pathIdx = 0; pathIdx < pathCountC; ++pathIdx)
		{
			// Generate camera path origin and direction			
			SubPathState cameraState;
			const Vec2f screenSample = GenerateCameraSample(pathIdx, cameraState);
			Rgb color(0);

			// We assume that the camera is on surface
			bool originInMedium = false;

			// Medium of the previous vertex
			const AbstractMedium* lastMedium = NULL;

			bool onlySpecSurf = (mEstimatorTechniques & (PREVIOUS | COMPATIBLE)) != 0;
			bool stopBB1D = false;

			//////////////////////////////////////////////////////////////////////
			// Trace camera path
			for (;; ++cameraState.mPathLength)
			{
				// Prepare ray
				Ray ray(cameraState.mOrigin, cameraState.mDirection);
				Isect isect(1e36f);

				// Trace ray
				mVolumeSegments.clear();
				mLiteVolumeSegments.clear();
				if (!mScene.Intersect(ray, originInMedium ? AbstractMedium::kOriginInMedium : 0, mRng, isect, cameraState.mBoundaryStack, mVolumeSegments, mLiteVolumeSegments))
				{
					//UPBP_ASSERT(!mScene.GetGlobalMediumPtr()->HasScattering());			

					// Vertex merging: beam x point 2D
					if (mMergeWithLightVerticesPB2D && !mLightVertices.empty())
					{
						mDebugImages.ResetAccum();
						uint estimatorTechniques = mEstimatorTechniques;
						//if (!cameraState.mSpecularPath) estimatorTechniques |= BEAM_REDUCTION;
						embree::AdditionalRayDataForMis data(&mLightVertices, &mPathEnds, &mCameraVerticesMisData, cameraState.mPathLength, mMinPathLength, mMaxPathLength, mQueryBeamType, mPhotonBeamType, cameraState.mLastPdfWInv, mSurfMisWeightFactor, mPP3DMisWeightFactor, mPB2DMisWeightFactor, mBB1DMisWeightFactor, (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty()) ? &mBB1DPhotonBeams : NULL, mBB1DMinMFP, mLightSubPathCount, mMinDistToMed, 0.0f, 0.0f, 0, &mDebugImages);
						const Rgb contrib = mPB2DEmbreeBre.evalBre(mQueryBeamType, ray, mVolumeSegments, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
						const Rgb mult = cameraState.mThroughput * mPB2DNormalization;
						color += mult * contrib;
						mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::PB2D, screenSample, mult);
					}

					// Vertex merging: beam x beam 1D
					if (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty() && !stopBB1D)
					{
						mDebugImages.ResetAccum();
						uint estimatorTechniques = mEstimatorTechniques;
						//if (!cameraState.mSpecularPath) estimatorTechniques |= BEAM_REDUCTION;
						embree::AdditionalRayDataForMis data(&mLightVertices, &mPathEnds, &mCameraVerticesMisData, cameraState.mPathLength, mMinPathLength, mMaxPathLength, mQueryBeamType, mPhotonBeamType, cameraState.mLastPdfWInv, mSurfMisWeightFactor, mPP3DMisWeightFactor, mPB2DMisWeightFactor, mBB1DMisWeightFactor, !mPhotonBeamsArray.empty() ? &mBB1DPhotonBeams : NULL, mBB1DMinMFP, mBB1DUsedLightSubPathCount, mMinDistToMed, 0.0f, 0.0f, 0, &mDebugImages);
						const Rgb contrib = mBB1DPhotonBeams.evalBeamBeamEstimate(mQueryBeamType, ray, mVolumeSegments, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
						const Rgb mult = cameraState.mThroughput * mBB1DNormalization;
						color += mult * contrib;
						mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::BB1D, screenSample, mult);
					}

					// We cannot end yet
					if (cameraState.mPathLength < mMinPathLength)
						break;

					// Get background light					
					const BackgroundLight* background = mScene.GetBackground();
					if (!background)
						break;

					// In attenuating media the ray can never travel to infinity
					if (mScene.GetGlobalMediumPtr()->HasAttenuation())
						break;

					// Stop if we are in the light sampling mode and could have sampled this light last time in the next event estimation
					if (mAlgorithm == kPTls && cameraState.mPathLength > 1 && !cameraState.mLastSpecular)
						break;

					// Attenuate by intersected media (if any)
					float raySamplePdf(1.0f);
					float raySampleRevPdf(1.0f);
					if (!mVolumeSegments.empty())
					{
						// PDF
						raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
						UPBP_ASSERT(raySamplePdf > 0);

						// Reverse PDF
						raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
						UPBP_ASSERT(raySampleRevPdf > 0);

						// Attenuation
						cameraState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;
					}

					if (cameraState.mThroughput.isBlackOrNegative())
						break;

					// Update affected MIS data
					const float raySamplePdfInv = 1.0f / raySamplePdf;
					mCameraVerticesMisData[cameraState.mPathLength].mPdfAInv = cameraState.mLastPdfWInv * raySamplePdfInv;
					mCameraVerticesMisData[cameraState.mPathLength].mRevPdfA = 1.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfInv = raySamplePdfInv;
					mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfInv = 1.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mSurfMisWeightFactor = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mPP3DMisWeightFactor = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mPB2DMisWeightFactor = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mBB1DMisWeightFactor = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mBB1DBeamSelectionPdf = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mIsDelta = false;
					mCameraVerticesMisData[cameraState.mPathLength].mIsOnLightSource = true;
					mCameraVerticesMisData[cameraState.mPathLength].mIsSpecular = false;
					mCameraVerticesMisData[cameraState.mPathLength].mInMediumWithBeams = false;
					mCameraVerticesMisData[cameraState.mPathLength - 1].mRevPdfA *= raySampleRevPdf;
					mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfInv = 1.0f / raySampleRevPdf;

					if (lastMedium && !lastMedium->IsHomogeneous()) // Homogeneous case was solved immediately when processing the vertex for the first time
					{
						float firstSegmentRayOverSampleRevPdf;
						lastMedium->RaySamplePdf(ray, mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
						const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We were in medium -> we know we have insampled
						mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
					}

					mDebugImages.ResetTemp();
					// Accumulate contribution
					color += cameraState.mThroughput *
						GetLightRadiance(mScene.GetBackground(), cameraState, Pos(0));
					const Rgb debugRgb = cameraState.mThroughput * mDebugImages.getTempRGB();
					mDebugImages.addSample(cameraState.mPathLength, 0, DebugImages::BPT, screenSample, debugRgb, debugRgb * mDebugImages.getTempMisWeight(), mDebugImages.getTempMisWeight());
					break;
				}

				UPBP_ASSERT(isect.IsValid());

				////////////////////////////////////////////////////////////////
				// Vertex merging: beam x point 2D
				if (mMergeWithLightVerticesPB2D && !mLightVertices.empty())
				{
					mDebugImages.ResetAccum();
					Rgb contrib(0);
					uint estimatorTechniques = mEstimatorTechniques;
					//if (!cameraState.mSpecularPath) estimatorTechniques |= BEAM_REDUCTION;
					embree::AdditionalRayDataForMis data(&mLightVertices, &mPathEnds, &mCameraVerticesMisData, cameraState.mPathLength, mMinPathLength, mMaxPathLength, mQueryBeamType, mPhotonBeamType, cameraState.mLastPdfWInv, mSurfMisWeightFactor, mPP3DMisWeightFactor, mPB2DMisWeightFactor, mBB1DMisWeightFactor, (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty()) ? &mBB1DPhotonBeams : NULL, mBB1DMinMFP, mLightSubPathCount, mMinDistToMed, 0.0f, 0.0f, 0, &mDebugImages);
					if (isect.IsOnSurface() || mQueryBeamType == SHORT_BEAM)
						contrib = mPB2DEmbreeBre.evalBre(mQueryBeamType, ray, mVolumeSegments, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
					else
						contrib = mPB2DEmbreeBre.evalBre(mQueryBeamType, ray, mLiteVolumeSegments, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
					const Rgb mult = cameraState.mThroughput * mPB2DNormalization;
					color += mult * contrib;
					mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::PB2D, screenSample, mult);
				}

				////////////////////////////////////////////////////////////////
				// Vertex merging: beam x beam 1D
				if (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty() && !stopBB1D)
				{
					mDebugImages.ResetAccum();
					Rgb contrib(0);
					uint estimatorTechniques = mEstimatorTechniques;
					//if (!cameraState.mSpecularPath) estimatorTechniques |= BEAM_REDUCTION;
					embree::AdditionalRayDataForMis data(&mLightVertices, &mPathEnds, &mCameraVerticesMisData, cameraState.mPathLength, mMinPathLength, mMaxPathLength, mQueryBeamType, mPhotonBeamType, cameraState.mLastPdfWInv, mSurfMisWeightFactor, mPP3DMisWeightFactor, mPB2DMisWeightFactor, mBB1DMisWeightFactor, !mPhotonBeamsArray.empty() ? &mBB1DPhotonBeams : NULL, mBB1DMinMFP, mBB1DUsedLightSubPathCount, mMinDistToMed, 0.0f, 0.0f, 0, &mDebugImages);
					if (isect.IsOnSurface() || mQueryBeamType == SHORT_BEAM)
						contrib = mBB1DPhotonBeams.evalBeamBeamEstimate(mQueryBeamType, ray, mVolumeSegments, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
					else
						contrib = mBB1DPhotonBeams.evalBeamBeamEstimate(mQueryBeamType, ray, mLiteVolumeSegments, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
					const Rgb mult = cameraState.mThroughput * mBB1DNormalization;
					color += mult * contrib;
					mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::BB1D, screenSample, mult);
				}

				// Attenuate by intersected media (if any)
				float raySamplePdf(1.0f);
				float raySampleRevPdf(1.0f);
				if (!mVolumeSegments.empty())
				{
					// PDF
					raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
					UPBP_ASSERT(raySamplePdf > 0);

					// Reverse PDF
					raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
					UPBP_ASSERT(raySampleRevPdf > 0);

					// Attenuation
					cameraState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;
				}

				if (cameraState.mThroughput.isBlackOrNegative())
					break;

				// Prepare scattering function at the hitpoint (BSDF/phase depending on whether the hitpoint is at surface or in media, the isect knows)
				BSDF bsdf(ray, isect, mScene, BSDF::kFromCamera, mScene.RelativeIOR(isect, cameraState.mBoundaryStack));

				if (!bsdf.IsValid()) // e.g. hitting surface too parallel with tangent plane
					break;

				// Compute hitpoint
				Pos hitPoint = ray.origin + ray.direction * isect.mDist;

				originInMedium = isect.IsInMedium();

				// Update affected MIS data
				{
					const float distSq = Utils::sqr(isect.mDist);
					const float raySamplePdfInv = 1.0f / raySamplePdf;
					mCameraVerticesMisData[cameraState.mPathLength].mPdfAInv = cameraState.mLastPdfWInv * distSq * raySamplePdfInv / std::abs(bsdf.CosThetaFix());
					mCameraVerticesMisData[cameraState.mPathLength].mRevPdfA = 1.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfInv = raySamplePdfInv;
					mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfInv = 1.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mSinTheta = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mSurfMisWeightFactor = bsdf.IsOnSurface() ? (isect.mLightID >= 0 ? 0.0f : mSurfMisWeightFactor) : 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mPP3DMisWeightFactor = bsdf.IsOnSurface() ? 0.0f : mPP3DMisWeightFactor;
					mCameraVerticesMisData[cameraState.mPathLength].mPB2DMisWeightFactor = bsdf.IsOnSurface() ? 0.0f : mPB2DMisWeightFactor;
					mCameraVerticesMisData[cameraState.mPathLength].mBB1DMisWeightFactor = bsdf.IsOnSurface() ? 0.0f : mBB1DMisWeightFactor;
					mCameraVerticesMisData[cameraState.mPathLength].mBB1DBeamSelectionPdf = bsdf.IsOnSurface() ? 0.0f : ((mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty() && mBB1DPhotonBeams.sMaxBeamsInCell) ? mBB1DPhotonBeams.getBeamSelectionPdf(hitPoint) : 1.0f);
					mCameraVerticesMisData[cameraState.mPathLength].mIsDelta = isect.mLightID >= 0 ? false : bsdf.IsDelta();
					mCameraVerticesMisData[cameraState.mPathLength].mIsOnLightSource = isect.mLightID >= 0;
					mCameraVerticesMisData[cameraState.mPathLength].mIsSpecular = false;
					mCameraVerticesMisData[cameraState.mPathLength].mInMediumWithBeams = bsdf.IsOnSurface() ? false : (!mMergeWithLightVerticesPB2D || bsdf.GetMedium()->GetMeanFreePath(hitPoint) > mBB1DMinMFP);

					mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = 0.0f;
					mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfsRatio = 0.0f;
					if (bsdf.IsInMedium())
					{
						if (bsdf.GetMedium()->IsHomogeneous())
						{
							mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = 1.0f / ((const HomogeneousMedium*)bsdf.GetMedium())->mMinPositiveAttenuationCoefCoord();
							mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfsRatio = mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio;
						}
						else
						{
							const float lastSegmentRayOverSamplePdf = bsdf.GetMedium()->RaySamplePdf(ray, mVolumeSegments.back().mDistMin, mVolumeSegments.back().mDistMax, 0);
							const float lastSegmentRayInSamplePdf = mVolumeSegments.back().mRaySamplePdf; // We are in medium -> we know we have insampled
							mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = lastSegmentRayOverSamplePdf / lastSegmentRayInSamplePdf;
						}
					}

					// Update reverse PDFs of the previous vertex
					mCameraVerticesMisData[cameraState.mPathLength - 1].mRevPdfA *= raySampleRevPdf / distSq;
					mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfInv = 1.0f / raySampleRevPdf;

					if (lastMedium && !lastMedium->IsHomogeneous()) // Homogeneous case was solved immediately when processing the vertex for the first time
					{
						float firstSegmentRayOverSampleRevPdf;
						lastMedium->RaySamplePdf(ray, mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
						const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We were in medium -> we know we have insampled
						mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
					}
				}

				// Light source has been hit; terminate afterwards, since
				// our light sources do not have reflective properties
				if (isect.mLightID >= 0)
				{
					// We cannot end yet
					if (cameraState.mPathLength < mMinPathLength)
						break;

					// Stop if we are in the light sampling mode and could have sampled this light last time in the next event estimation
					if (mAlgorithm == kPTls && cameraState.mPathLength > 1 && !cameraState.mLastSpecular)
						break;

					// Get hit light
					const AbstractLight *light = mScene.GetLightPtr(isect.mLightID);
					UPBP_ASSERT(light);

					// Add its contribution
					mDebugImages.ResetTemp();
					const Rgb contrib = cameraState.mThroughput *
						GetLightRadiance(light, cameraState, hitPoint);
					color += contrib;
					const Rgb debugRgb = cameraState.mThroughput * mDebugImages.getTempRGB();
					mDebugImages.addSample(cameraState.mPathLength, 0, DebugImages::BPT, screenSample, debugRgb, debugRgb * mDebugImages.getTempMisWeight(), mDebugImages.getTempMisWeight());
					break;
				}

				// Terminate if eye sub-path is too long for connections or merging
				if (cameraState.mPathLength >= mMaxPathLength)
					break;

				// Ignore contribution of primary rays from medium too close to camera
				if (cameraState.mPathLength > 1 || bsdf.IsOnSurface() || isect.mDist >= mMinDistToMed)
				{
					////////////////////////////////////////////////////////////////
					// Vertex connection: Connect to a light source
					if (mConnectToLightSource && !bsdf.IsDelta() && cameraState.mPathLength + 1 >= mMinPathLength && mScene.GetLightCount() > 0 && (bsdf.IsInMedium() || !onlySpecSurf))
					{
						mDebugImages.ResetTemp();
						color += cameraState.mThroughput *
							DirectIllumination(cameraState, hitPoint, bsdf);
						const Rgb debugRgb = cameraState.mThroughput * mDebugImages.getTempRGB();
						mDebugImages.addSample(cameraState.mPathLength + 1, 0, DebugImages::BPT, screenSample, debugRgb, debugRgb * mDebugImages.getTempMisWeight(), mDebugImages.getTempMisWeight());
					}

					////////////////////////////////////////////////////////////////
					// Vertex connection: Connect to light vertices
					if (mConnectToLightVertices && !bsdf.IsDelta() && !mLightVertices.empty() && (bsdf.IsInMedium() || !onlySpecSurf))
					{
						// Determine whether the vertex is in medium behind real geometry
						bool behindSurf = false;
						if (bsdf.IsInMedium() && !cameraState.mBoundaryStack.IsEmpty())
						{
							int matId = cameraState.mBoundaryStack.Top().mMaterialId;
							if (matId >= 0)
							{
								const Material& mat = mScene.GetMaterial(matId);
								if (mat.mGeometryType != GeometryType::IMAGINARY)
									behindSurf = true;
							}
						}

						int pathIdxMod = mRng.GetUint() % pathCountL;

						// For VC, each light sub-path is assigned to a particular eye
						// sub-path, as in traditional BPT. It is also possible to
						// connect to vertices from any light path, but MIS should
						// be revisited.
						const Vec2i range(
							(pathIdxMod == 0) ? 0 : mPathEnds[pathIdxMod - 1],
							mPathEnds[pathIdxMod]);

						for (int i = range[0]; i < range[1]; i++)
						{
							const UPBPLightVertex &lightVertex = mLightVertices[i];

							if (lightVertex.mPathLength + 1 +
								cameraState.mPathLength < mMinPathLength)
								continue;

							// Light vertices are stored in increasing path length
							// order; once we go above the max path length, we can
							// skip the rest
							if (lightVertex.mPathLength + 1 +
								cameraState.mPathLength > mMaxPathLength)
								break;

							// We store all light vertices in order to compute MIS weights but not all can be used for VC
							if (!lightVertex.mConnectable)
								continue;

							// Don't try connect vertices in different media with real geometry
							if (lightVertex.mBSDF.IsInMedium() && bsdf.IsInMedium() && lightVertex.mBSDF.GetMedium() != bsdf.GetMedium()
								&& (lightVertex.mBehindSurf || behindSurf))
								continue;

							const Rgb mult = cameraState.mThroughput * lightVertex.mThroughput;
							mDebugImages.ResetTemp();
							color += mult * ConnectVertices(lightVertex, bsdf, hitPoint, cameraState);
							const Rgb debugRgb = mult * mDebugImages.getTempRGB();
							mDebugImages.addSample(cameraState.mPathLength + 1, lightVertex.mPathLength, DebugImages::BPT, screenSample, debugRgb, debugRgb * mDebugImages.getTempMisWeight(), mDebugImages.getTempMisWeight());
						}
					}

					////////////////////////////////////////////////////////////////
					// Vertex merging: surface photon mapping
					if (mMergeWithLightVerticesSurf && bsdf.IsOnSurface() && !bsdf.IsDelta() && mLightVerticesOnSurfaceCount > 0 && !onlySpecSurf)
					{
						mDebugImages.ResetAccum();
						RangeQuery query(*this, hitPoint, bsdf, cameraState, mDebugImages);
						mSurfHashGrid.Process(mLightVertices, query);
						const Rgb mult = cameraState.mThroughput * mSurfNormalization;
						color += mult * query.GetContrib();
						mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::SURFACE_PHOTON_MAPPING, screenSample, mult);

						// PPM merges only at the first non-specular surface from camera
						if (mAlgorithm == kPPM) break;
					}

					////////////////////////////////////////////////////////////////
					// Vertex merging: point x point 3D
					if (mMergeWithLightVerticesPP3D && bsdf.IsInMedium() && !bsdf.IsDelta() && mLightVerticesInMediumCount > 0)
					{
						mDebugImages.ResetAccum();
						RangeQuery query(*this, hitPoint, bsdf, cameraState, mDebugImages);
						mPP3DHashGrid.Process(mLightVertices, query);
						const Rgb mult = cameraState.mThroughput * mPP3DNormalization;
						color += mult * query.GetContrib();
						mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::PP3D, screenSample, mult);
					}
				}

				// Continue random walk
				if (!SampleScattering(bsdf, hitPoint, isect, cameraState, mCameraVerticesMisData[cameraState.mPathLength], mCameraVerticesMisData[cameraState.mPathLength - 1]))
					break;

				if (bsdf.IsOnSurface())
				{
					if (!cameraState.mLastSpecular)
					{
						if (onlySpecSurf || (mEstimatorTechniques & SPECULAR_ONLY))
							break;

						if (mEstimatorTechniques & BB1D_PREVIOUS)
							stopBB1D = true;
					}

					lastMedium = NULL;
				}
				else
				{
					if (mEstimatorTechniques & SPECULAR_ONLY)
						break;

					if (onlySpecSurf)
					{
						if (mEstimatorTechniques & COMPATIBLE)
							onlySpecSurf = false;
						else
							break;
					}

					if (mEstimatorTechniques & BB1D_PREVIOUS)
						stopBB1D = true;

					lastMedium = bsdf.GetMedium();
				}
			}

			mFramebuffer.AddColor(screenSample, color);
		}

		mTimer.Stop();
		if (mVerbose)
			std::cout << std::setprecision(3) << "   - camera sub-path tracing done in " << mTimer.GetLastElapsedTime() << " sec. " << std::endl;

		mCameraTracingTime += mTimer.GetLastElapsedTime();

		// Delete stored photons
		if (mMergeWithLightVerticesPB2D && mMaxPathLength > 1 && !mLightVertices.empty())
		{
			mPB2DEmbreeBre.destroy();
		}

		// Delete stored photon beams
		if (mMergeWithLightVerticesBB1D && mMaxPathLength > 1 && !mPhotonBeamsArray.empty())
		{
			mBB1DPhotonBeams.destroy();
		}

		mIterations++;
	}

private:

	//////////////////////////////////////////////////////////////////////////
	// Camera tracing methods
	//////////////////////////////////////////////////////////////////////////

	// Generates new camera sample given a pixel index
	Vec2f GenerateCameraSample(
		const int    aPixelIndex,
		SubPathState &oCameraState)
	{
		const Camera &camera = mScene.mCamera;
		const int resX = int(camera.mResolution.get(0));
		const int resY = int(camera.mResolution.get(1));
		
		// Determine pixel (x, y)
		const int x = aPixelIndex % resX;
		const int y = aPixelIndex / resX;

		// Jitter pixel position
		const Vec2f sample = Vec2f(float(x), float(y)) + mRng.GetVec2f();

		// Generate ray
		const Ray primaryRay = camera.GenerateRay(sample);

		// Compute PDF conversion factor from area on image plane to solid angle on ray
		const float cosAtCamera = dot(camera.mDirection, primaryRay.direction);
		const float imagePointToCameraDist = camera.mImagePlaneDist / cosAtCamera;
		const float imageToSolidAngleFactor = Utils::sqr(imagePointToCameraDist) / cosAtCamera;

		// We put the virtual image plane at such a distance from the camera origin
		// that the pixel area is one and thus the image plane sampling PDF is 1.
		// The solid angle ray PDF is then equal to the conversion factor from
		// image plane area density to ray solid angle density
		const float cameraPdfW = imageToSolidAngleFactor;

		oCameraState.mOrigin = primaryRay.origin;
		oCameraState.mDirection = primaryRay.direction;
		oCameraState.mThroughput = Rgb(1);
		oCameraState.mPathLength = 1;
		oCameraState.mSpecularPath = 1;
		oCameraState.mLastSpecular = true;
		oCameraState.mLastPdfWInv = mScreenPixelCount / cameraPdfW;

		// Init the boundary stack with the global medium and add enclosing material and medium if present
		mScene.InitBoundaryStack(oCameraState.mBoundaryStack);
		if (camera.mMatID != -1 && camera.mMedID != -1) mScene.AddToBoundaryStack(camera.mMatID, camera.mMedID, oCameraState.mBoundaryStack);

		return sample;
	}

	// Returns the radiance of a light source when hit by a random ray,
	// multiplied by MIS weight. Can be used for both Background and Area lights.
	Rgb GetLightRadiance(
		const AbstractLight *aLight,
		const SubPathState  &aCameraState,
		const Pos           &aHitpoint) const
	{
		if (aCameraState.mSpecularPath == 1 && mIgnoreFullySpecPaths)
			return Rgb(0);
		// We sample lights uniformly
		const int   lightCount = mScene.GetLightCount();
		const float lightPickProb = 1.f / lightCount;

		float directPdfA, emissionPdfW;
		const Rgb radiance = aLight->GetRadiance(mScene.mSceneSphere,
			aCameraState.mDirection, aHitpoint, &directPdfA, &emissionPdfW);

		if (radiance.isBlackOrNegative())
			return Rgb(0);

		// If we see light source directly from camera, no weighting is required
		if (aCameraState.mPathLength == 1)
		{
			mDebugImages.setTempRgbWeight(radiance, 1.0f);
			return radiance;
		}

		// When using only vertex merging, we want purely specular paths
		// to give radiance (cannot get it otherwise). Rest is handled
		// by merging and we should return 0.
		if (mEstimatorTechniques && !(mEstimatorTechniques & BPT))
			return aCameraState.mSpecularPath ? radiance : Rgb(0);

		directPdfA *= lightPickProb;
		emissionPdfW *= lightPickProb;

		UPBP_ASSERT(directPdfA > 0);
		UPBP_ASSERT(emissionPdfW > 0);

		// MIS weight
		float misWeight = 1.f;
		if (mConnectToLightVertices)
		{
			UPBP_ASSERT(directPdfA > 0);
			const float wCamera = AccumulateCameraPathWeight2(aCameraState.mPathLength, directPdfA, 0, 0, 0, emissionPdfW / directPdfA);
			misWeight = 1.0f / (wCamera + 1.f);
		}
		else if (mAlgorithm == kPTmis && !aCameraState.mLastSpecular)
		{
			const float wCamera = directPdfA * mCameraVerticesMisData[aCameraState.mPathLength].mPdfAInv;
			misWeight = 1.0f / (wCamera + 1.f);
		}

		mDebugImages.setTempRgbWeight(radiance,misWeight);
		return misWeight * radiance;
	}

	// Connects camera vertex to randomly chosen light point.
	// Returns emitted radiance multiplied by path MIS weight.
	// Has to be called AFTER updating the MIS quantities.
	Rgb DirectIllumination(
		const SubPathState  &aCameraState,
		const Pos           &aHitpoint,
		const BSDF          &aCameraBSDF)
	{
		// We sample lights uniformly
		const int   lightCount = mScene.GetLightCount();
		const float lightPickProb = 1.f / lightCount;

		const int   lightID = int(mRng.GetFloat() * lightCount);
		const Vec2f rndPosSamples = mRng.GetVec2f();

		const AbstractLight *light = mScene.GetLightPtr(lightID);
		UPBP_ASSERT(light);

		// Light in infinity in attenuating homogeneous global medium is always reduced to zero
		if (!light->IsFinite() && mScene.GetGlobalMediumPtr()->HasAttenuation())
			return Rgb(0);

		Dir directionToLight;
		float distance;
		float directPdfW, emissionPdfW, cosAtLight;
		const Rgb radiance = light->Illuminate(mScene.mSceneSphere, aHitpoint,
			rndPosSamples, directionToLight, distance, directPdfW,
			&emissionPdfW, &cosAtLight);

		// If radiance == 0, other values are undefined, so shave to early exit
		if (radiance.isBlackOrNegative())
			return Rgb(0);

		UPBP_ASSERT(directPdfW > 0);
		UPBP_ASSERT(emissionPdfW > 0);
		UPBP_ASSERT(cosAtLight > 0);

		// Get BSDF factor at the last camera vertex
		float bsdfDirPdfW, bsdfRevPdfW, cosToLight, sinTheta;
		Rgb bsdfFactor = aCameraBSDF.Evaluate(directionToLight, cosToLight, &bsdfDirPdfW, &bsdfRevPdfW, &sinTheta);

		if (bsdfFactor.isBlackOrNegative())
			return Rgb(0);

		const float continuationProbability = aCameraBSDF.ContinuationProb();

		// If the light is delta light, we can never hit it
		// by BSDF sampling, so the probability of this path is 0
		bsdfDirPdfW *= light->IsDelta() ? 0.f : continuationProbability;
		bsdfRevPdfW *= continuationProbability;

		UPBP_ASSERT(bsdfRevPdfW > 0);
		UPBP_ASSERT(cosToLight > 0);

		Rgb contrib(0);

		// Test occlusion
		mVolumeSegments.clear();
		if (!mScene.Occluded(aHitpoint, directionToLight, distance, aCameraState.mBoundaryStack, aCameraBSDF.IsInMedium() ? AbstractMedium::kOriginInMedium : 0, mVolumeSegments))
		{
			// Get attenuation from intersected media (if any)
			float nextRaySamplePdf(1.0f);
			float nextRaySampleRevPdf(1.0f);
			Rgb nextAttenuation(1.0f);
			if (!mVolumeSegments.empty())
			{
				// PDF
				nextRaySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
				UPBP_ASSERT(nextRaySamplePdf > 0);

				// Reverse PDF
				nextRaySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
				UPBP_ASSERT(nextRaySampleRevPdf > 0);

				// Attenuation (without PDF!)
				nextAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
				if (!nextAttenuation.isPositive())
					return Rgb(0);
			}

			// MIS weight
			float misWeight = 1.f;
			if (mConnectToLightVertices)
			{
				float lastSinTheta = 0;
				float lastRaySampleRevPdfInv = 0;
				float lastRaySampleRevPdfsRatio = 0;
				if (aCameraBSDF.IsInMedium())
				{
					lastSinTheta = sinTheta;
					lastRaySampleRevPdfInv = 1.0f / nextRaySampleRevPdf;
					lastRaySampleRevPdfsRatio = mCameraVerticesMisData[aCameraState.mPathLength].mRaySamplePdfsRatio;
					if (!aCameraBSDF.GetMedium()->IsHomogeneous())
					{
						float firstSegmentRayOverSampleRevPdf;
						aCameraBSDF.GetMedium()->RaySamplePdf(Ray(aCameraState.mOrigin, aCameraState.mDirection), mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
						const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We are in medium -> we know we have insampled
						lastRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
					}
				}
				
				// For wCamera we need ratio = emissionPdfA / directPdfA,
				// with emissionPdfA being the product of the PDFs for choosing the
				// point on the light source and sampling the outgoing direction.
				// What we are given by the light source instead are emissionPdfW
				// and directPdfW. Converting to area PDFs and plugging into ratio:
				//    emissionPdfA = emissionPdfW * cosToLight / dist^2
				//    directPdfA   = directPdfW * cosAtLight / dist^2
				//    ratio = (emissionPdfW * cosToLight / dist^2) / (directPdfW * cosAtLight / dist^2)
				//    ratio = (emissionPdfW * cosToLight) / (directPdfW * cosAtLight)
				// Also note that both emissionPdfW and directPdfW should be
				// multiplied by lightPickProb, so it cancels out.
				UPBP_ASSERT(nextRaySampleRevPdf * emissionPdfW * cosToLight / (directPdfW * cosAtLight) > 0);
				const float wCamera = AccumulateCameraPathWeight2(aCameraState.mPathLength, nextRaySampleRevPdf * emissionPdfW * cosToLight / (directPdfW * cosAtLight), lastSinTheta, lastRaySampleRevPdfInv, lastRaySampleRevPdfsRatio, bsdfRevPdfW);

				// Note that wLight is a ratio of area PDFs. But since both are on the
				// light source, their distance^2 and cosine terms cancel out.
				// Therefore we can write wLight as a ratio of solid angle PDFs,
				// both expressed w.r.t. the same shading point.
				const float wLight = light->IsDelta() ? 0 : (nextRaySamplePdf * bsdfDirPdfW) / (directPdfW * lightPickProb);
				misWeight = 1.0f / (wCamera + 1.f + wLight);
			}
			else if (mAlgorithm != kPTls && !light->IsDelta())
				misWeight = Mis2(lightPickProb * directPdfW, bsdfDirPdfW * nextRaySamplePdf);

			contrib = (cosToLight / (lightPickProb * directPdfW)) * (radiance * nextAttenuation * bsdfFactor);
			mDebugImages.setTempRgbWeight(contrib, misWeight);
			contrib *= misWeight;
		}

		if (contrib.isBlackOrNegative())
		{
			mDebugImages.ResetTemp();
			return Rgb(0);
		}

		return contrib;
	}

	// Connects an eye and a light vertex. Result multiplied by MIS weight, but
	// not multiplied by vertex throughputs. Has to be called AFTER updating MIS
	// constants. 'direction' is FROM eye TO light vertex.
	Rgb ConnectVertices(
		const UPBPLightVertex &aLightVertex,
		const BSDF           &aCameraBSDF,
		const Pos            &aCameraHitpoint,
		const SubPathState   &aCameraState)
	{
		// Get the connection
		Dir direction = aLightVertex.mHitpoint - aCameraHitpoint;
		const float dist2 = direction.square();
		float  distance = std::sqrt(dist2);
		direction /= distance;

		// Evaluate BSDF at camera vertex
		float cosCamera, cameraBsdfDirPdfW, cameraBsdfRevPdfW, sinThetaCamera;
		Rgb cameraBsdfFactor = aCameraBSDF.Evaluate(
			direction, cosCamera, &cameraBsdfDirPdfW,
			&cameraBsdfRevPdfW, &sinThetaCamera);

		if (cameraBsdfFactor.isBlackOrNegative())
			return Rgb(0);

		// Camera continuation probability (for Russian roulette)
		const float cameraCont = aCameraBSDF.ContinuationProb();
		cameraBsdfDirPdfW *= cameraCont;
		cameraBsdfRevPdfW *= cameraCont;
		UPBP_ASSERT(cameraBsdfDirPdfW > 0);
		UPBP_ASSERT(cameraBsdfRevPdfW > 0);

		// Evaluate BSDF at light vertex
		float cosLight, lightBsdfDirPdfW, lightBsdfRevPdfW, sinThetaLight;
		const Rgb lightBsdfFactor = aLightVertex.mBSDF.Evaluate(
			-direction, cosLight, &lightBsdfDirPdfW,
			&lightBsdfRevPdfW, &sinThetaLight);

		if (lightBsdfFactor.isBlackOrNegative())
			return Rgb(0);

		// Light continuation probability (for Russian roulette)
		const float lightCont = aLightVertex.mBSDF.ContinuationProb();
		lightBsdfDirPdfW *= lightCont;
		lightBsdfRevPdfW *= lightCont;
		UPBP_ASSERT(lightBsdfDirPdfW > 0);
		UPBP_ASSERT(lightBsdfRevPdfW > 0);

		// Compute geometry term
		const float geometryTerm = cosLight * cosCamera / dist2;
		if (geometryTerm < 0)
			return Rgb(0);

		// Convert PDFs to area PDF
		const float cameraBsdfDirPdfA = PdfWtoA(cameraBsdfDirPdfW, distance, cosLight);
		const float lightBsdfDirPdfA = PdfWtoA(lightBsdfDirPdfW, distance, cosCamera);
		UPBP_ASSERT(cameraBsdfDirPdfA > 0);
		UPBP_ASSERT(lightBsdfDirPdfA > 0);

		uint raySamplingFlags = 0;
		if (aCameraBSDF.IsInMedium()) raySamplingFlags |= AbstractMedium::kOriginInMedium;
		if (aLightVertex.mInMedium)   raySamplingFlags |= AbstractMedium::kEndInMedium;

		// Test occlusion
		mVolumeSegments.clear();
		if (mScene.Occluded(aCameraHitpoint, direction, distance, aCameraState.mBoundaryStack, raySamplingFlags, mVolumeSegments))
			return Rgb(0);

		// Attenuate by intersected media (if any)
		float raySamplePdf(1.0f);
		float raySampleRevPdf(1.0f);
		Rgb mediaAttenuation(1.0f);
		if (!mVolumeSegments.empty())
		{
			// PDF
			raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
			UPBP_ASSERT(raySamplePdf > 0);

			// Reverse PDF
			raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
			UPBP_ASSERT(raySampleRevPdf > 0);

			// Attenuation (without PDF!)
			mediaAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
			if (!mediaAttenuation.isPositive())
				return Rgb(0);
		}

		// MIS weight
		
		// Camera part
		float lastSinThetaCamera = 0;
		float lastRaySampleRevPdfInvCamera = 0;
		float lastRaySampleRevPdfsRatioCamera = 0;
		if (aCameraBSDF.IsInMedium())
		{
			lastSinThetaCamera = sinThetaCamera;
			lastRaySampleRevPdfInvCamera = 1.0f / raySampleRevPdf;
			lastRaySampleRevPdfsRatioCamera = mCameraVerticesMisData[aCameraState.mPathLength].mRaySamplePdfsRatio;
			if (!aCameraBSDF.GetMedium()->IsHomogeneous())
			{
				float firstSegmentRayOverSampleRevPdf;
				aCameraBSDF.GetMedium()->RaySamplePdf(Ray(aCameraState.mOrigin, aCameraState.mDirection), mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
				const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We are in medium -> we know we have insampled
				lastRaySampleRevPdfsRatioCamera = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
			}
		}
		UPBP_ASSERT(raySampleRevPdf * lightBsdfDirPdfA > 0);
		const float wCamera = AccumulateCameraPathWeight2(aCameraState.mPathLength, raySampleRevPdf * lightBsdfDirPdfA, lastSinThetaCamera, lastRaySampleRevPdfInvCamera, lastRaySampleRevPdfsRatioCamera, cameraBsdfRevPdfW);
		
		// Light part
		float lastSinThetaLight = 0;
		float lastRaySampleRevPdfInvLight = 0;
		float lastRaySampleRevPdfsRatioLight = 0;
		if (aLightVertex.mInMedium)
		{
			lastSinThetaLight = sinThetaLight;
			lastRaySampleRevPdfInvLight = 1.0f / raySamplePdf;
			lastRaySampleRevPdfsRatioLight = aLightVertex.mMisData.mRaySamplePdfsRatio;
			if (!aLightVertex.mBSDF.GetMedium()->IsHomogeneous())
			{
				const float lastSegmentRayOverSamplePdf = aLightVertex.mBSDF.GetMedium()->RaySamplePdf(Ray(aCameraState.mOrigin, aCameraState.mDirection), mVolumeSegments.back().mDistMin, mVolumeSegments.back().mDistMax, 0);
				const float lastSegmentRayInSamplePdf = mVolumeSegments.back().mRaySamplePdf; // We are in medium -> we know we have insampled
				lastRaySampleRevPdfsRatioLight = lastSegmentRayOverSamplePdf / lastSegmentRayInSamplePdf;
			}
		}
		UPBP_ASSERT(raySamplePdf * cameraBsdfDirPdfA > 0);
		const float wLight = AccumulateLightPathWeight2(aLightVertex.mPathIdx, aLightVertex.mPathLength, raySamplePdf * cameraBsdfDirPdfA, lastSinThetaLight, lastRaySampleRevPdfInvLight, lastRaySampleRevPdfsRatioLight, lightBsdfRevPdfW, BPT, false);
		const float misWeight = 1.f / (wCamera + 1.f + wLight);

		Rgb contrib = (geometryTerm) * cameraBsdfFactor * lightBsdfFactor * mediaAttenuation;
		mDebugImages.setTempRgbWeight(contrib, misWeight);
		contrib *= misWeight;

		if (contrib.isBlackOrNegative())
		{
			mDebugImages.ResetTemp();
			return Rgb(0);
		}

		return contrib;
	}

	// Accumulates PDF ratios of all sampling techniques along path originally sampled from camera
	inline float AccumulateCameraPathWeight2(
		const int   aPathLength, 
		const float aLastRevPdfA,
		const float aLastSinTheta,
		const float aLastRaySampleRevPdfInv,
		const float aLastRaySampleRevPdfsRatio,
		const float aNextToLastPartialRevPdfW) const
	{
		return AccumulateCameraPathWeight(aPathLength, aLastRevPdfA, aLastSinTheta, aLastRaySampleRevPdfInv, aLastRaySampleRevPdfsRatio, aNextToLastPartialRevPdfW, mQueryBeamType, mPhotonBeamType, mEstimatorTechniques, mCameraVerticesMisData);
	}

	//////////////////////////////////////////////////////////////////////////
	// Light tracing methods
	//////////////////////////////////////////////////////////////////////////

	// Samples light emission
	void GenerateLightSample(int aPathIdx, SubPathState &oLightState)
	{
		// We sample lights uniformly
		const int   lightCount = mScene.GetLightCount();
		const float lightPickProb = 1.f / lightCount;

		const int   lightID = int(mRng.GetFloat() * lightCount);
		const Vec2f rndDirSamples = mRng.GetVec2f();
		const Vec2f rndPosSamples = mRng.GetVec2f();

		const AbstractLight *light = mScene.GetLightPtr(lightID);
		UPBP_ASSERT(light);

		float emissionPdfW, directPdfA, cosLight;
		oLightState.mThroughput = light->Emit(mScene.mSceneSphere, rndDirSamples, rndPosSamples,
			oLightState.mOrigin, oLightState.mDirection,
			emissionPdfW, &directPdfA, &cosLight);

		emissionPdfW *= lightPickProb;
		directPdfA *= lightPickProb;

		UPBP_ASSERT(emissionPdfW);
		UPBP_ASSERT(directPdfA);

		// Store vertex

		UPBPLightVertex lightVertex;
		lightVertex.mHitpoint = oLightState.mOrigin;
		lightVertex.mThroughput = Rgb(1.0f);
		lightVertex.mPathLength = 0;
		lightVertex.mPathIdx = aPathIdx;
		lightVertex.mInMedium = false;
		lightVertex.mConnectable = false;
		lightVertex.mIsFinite = light->IsFinite();

		lightVertex.mMisData.mPdfAInv = 1.0f / directPdfA;
		lightVertex.mMisData.mRevPdfA = light->IsDelta() ? 0.0f : (light->IsFinite() ? cosLight : 1.f);
		lightVertex.mMisData.mRevPdfAWithoutBsdf = lightVertex.mMisData.mRevPdfA;
		lightVertex.mMisData.mRaySamplePdfInv = 0.0f;
		lightVertex.mMisData.mRaySampleRevPdfInv = 1.0f;
		lightVertex.mMisData.mRaySamplePdfsRatio = 0.0f;
		lightVertex.mMisData.mRaySampleRevPdfsRatio = 0.0f;
		lightVertex.mMisData.mSinTheta = 0.0f;
		lightVertex.mMisData.mCosThetaOut = lightVertex.mMisData.mRevPdfA;
		lightVertex.mMisData.mSurfMisWeightFactor = 0.0f;
		lightVertex.mMisData.mPP3DMisWeightFactor = 0.0f;
		lightVertex.mMisData.mPB2DMisWeightFactor = 0.0f;
		lightVertex.mMisData.mBB1DMisWeightFactor = 0.0f;
		lightVertex.mMisData.mBB1DBeamSelectionPdf = 0.0f;
		lightVertex.mMisData.mIsDelta = light->IsDelta();
		lightVertex.mMisData.mIsOnLightSource = true;
		lightVertex.mMisData.mIsSpecular = false;
		lightVertex.mMisData.mInMediumWithBeams = false;

		mLightVerticesOnSurfaceCount++;
		mLightVertices.push_back(lightVertex);

		// Complete light path state initialization

		oLightState.mThroughput /= emissionPdfW;
		oLightState.mPathLength = 1;
		oLightState.mIsFiniteLight = light->IsFinite() ? 1 : 0;
		oLightState.mLastSpecular = false;
		oLightState.mLastPdfWInv = directPdfA / emissionPdfW;

		// Init the boundary stack with the global medium and add enclosing material and medium if present
		mScene.InitBoundaryStack(oLightState.mBoundaryStack);
		if (light->mMatID != -1 && light->mMedID != -1) mScene.AddToBoundaryStack(light->mMatID, light->mMedID, oLightState.mBoundaryStack);
	}

	// Computes contribution of light sample to camera by splatting is onto the
	// framebuffer. Multiplies by throughput (obviously, as nothing is returned).
	void ConnectToCamera(
		const int          aLightPathIdx,
		const SubPathState &aLightState,
		const Pos          &aHitpoint,
		const BSDF         &aLightBSDF,
		const float        aRaySampleRevPdfsRatio)
	{
		// Get camera and direction to it
		const Camera &camera = mScene.mCamera;
		Dir directionToCamera = camera.mOrigin - aHitpoint;

		// Check point is in front of camera
		if (dot(camera.mDirection, -directionToCamera) <= 0.f)
			return;

		// Check it projects to the screen (and where)
		const Vec2f imagePos = camera.WorldToRaster(aHitpoint);
		if (!camera.CheckRaster(imagePos))
			return;

		// Compute distance and normalize direction to camera
		const float distEye2 = directionToCamera.square();
		const float distance = std::sqrt(distEye2);
		directionToCamera /= distance;

		// Ignore contribution of primary rays from medium too close to camera
		if (aLightBSDF.IsInMedium() && distance < mMinDistToMed)
			return;

		// Get the BSDF factor
		float cosToCamera, bsdfDirPdfW, bsdfRevPdfW, sinTheta;
		Rgb bsdfFactor = aLightBSDF.Evaluate(directionToCamera, cosToCamera, &bsdfDirPdfW, &bsdfRevPdfW, &sinTheta);

		if (bsdfFactor.isBlackOrNegative())
			return;

		bsdfRevPdfW *= aLightBSDF.ContinuationProb();

		UPBP_ASSERT(bsdfDirPdfW > 0);
		UPBP_ASSERT(bsdfRevPdfW > 0);
		UPBP_ASSERT(cosToCamera > 0);

		// Compute PDF conversion factor from image plane area to surface area
		const float cosAtCamera = dot(camera.mDirection, -directionToCamera);
		const float imagePointToCameraDist = camera.mImagePlaneDist / cosAtCamera;
		const float imageToSolidAngleFactor = Utils::sqr(imagePointToCameraDist) / cosAtCamera;
		const float imageToSurfaceFactor = imageToSolidAngleFactor * std::abs(cosToCamera) / Utils::sqr(distance);

		// We put the virtual image plane at such a distance from the camera origin
		// that the pixel area is one and thus the image plane sampling PDF is 1.
		// The area PDF of aHitpoint as sampled from the camera is then equal to
		// the conversion factor from image plane area density to surface area density
		const float cameraPdfA = imageToSurfaceFactor;
		UPBP_ASSERT(cameraPdfA > 0);

		const float surfaceToImageFactor = 1.f / imageToSurfaceFactor;

		// Test occlusion
		mVolumeSegments.clear();
		if (!mScene.Occluded(aHitpoint, directionToCamera, distance, aLightState.mBoundaryStack, aLightBSDF.IsInMedium() ? AbstractMedium::kOriginInMedium : 0, mVolumeSegments))
		{
			// Get attenuation from intersected media (if any)
			float raySampleRevPdf(1.0f);
			Rgb mediaAttenuation(1.0f);
			if (!mVolumeSegments.empty())
			{
				// Reverse PDF
				raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
				UPBP_ASSERT(raySampleRevPdf > 0);

				// Attenuation (without PDF!)
				mediaAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
				if (!mediaAttenuation.isPositive())
					return;
			}

			// Compute MIS weight if not doing LT
			float misWeight = 1.f;
			if (mAlgorithm != kLT)
			{
				float lastSinTheta = 0;
				float lastRaySampleRevPdfInv = 0;
				float lastRaySampleRevPdfsRatio = 0;
				if (aLightBSDF.IsInMedium())
				{
					lastSinTheta = sinTheta;
					lastRaySampleRevPdfInv = 1.0f / raySampleRevPdf;
					lastRaySampleRevPdfsRatio = aRaySampleRevPdfsRatio;
					if (!aLightBSDF.GetMedium()->IsHomogeneous())
					{
						float firstSegmentRayOverSampleRevPdf;
						aLightBSDF.GetMedium()->RaySamplePdf(Ray(aLightState.mOrigin, aLightState.mDirection), mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
						const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We are in medium -> we know we have insampled
						lastRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
					}
				}
				UPBP_ASSERT(raySampleRevPdf * cameraPdfA > 0);
				const float wLight = AccumulateLightPathWeight2(aLightPathIdx, aLightState.mPathLength, raySampleRevPdf * cameraPdfA, lastSinTheta, lastRaySampleRevPdfInv, lastRaySampleRevPdfsRatio, bsdfRevPdfW, BPT, true) / mScreenPixelCount;
				misWeight = 1.0f / (1.f + wLight);
			}

			// We divide the contribution by surfaceToImageFactor to convert the (already
			// divided) PDF from surface area to image plane area, w.r.t. which the
			// pixel integral is actually defined. We also divide by the number of samples
			// this technique makes, which is equal to the number of light sub-paths
			Rgb contrib = aLightState.mThroughput * bsdfFactor * mediaAttenuation / (mLightSubPathCount * surfaceToImageFactor);			

			if (contrib.isBlackOrNegative())
				return;

			mDebugImages.addSample(0, aLightState.mPathLength + 1, DebugImages::BPT, imagePos, contrib, contrib * misWeight, misWeight);

			contrib *= misWeight;

			mFramebuffer.AddColor(imagePos, contrib);
		}
	}

	// Adds beams to beams array
	void AddBeams(
		const Ray &aRay,
		const Rgb &aThroughput,
		UPBPLightVertex *aLightVertex,
		const uint aRaySamplingFlags,
		const float aLastPdfWInv
		)
	{
		UPBP_ASSERT(aRaySamplingFlags == 0 || aRaySamplingFlags == AbstractMedium::kOriginInMedium);
		UPBP_ASSERT(aLightVertex);
		
		Rgb throughput = aThroughput;
		float raySamplePdf = 1.0f;
		float raySampleRevPdf = 1.0f;

		if (mPhotonBeamType == SHORT_BEAM)
		{
			for (VolumeSegments::const_iterator it = mVolumeSegments.cbegin(); it != mVolumeSegments.cend(); ++it)
			{
				UPBP_ASSERT(it->mMediumID >= 0);
				PhotonBeam beam;
				beam.mMedium = mScene.mMedia[it->mMediumID];
				if (beam.mMedium->HasScattering() && (!mMergeWithLightVerticesPB2D || beam.mMedium->GetMeanFreePath(aRay.origin) > mBB1DMinMFP))
				{
					beam.mRay = Ray(aRay.origin + aRay.direction * it->mDistMin, aRay.direction);
					beam.mLength = it->mDistMax - it->mDistMin;
					beam.mFlags = SHORT_BEAM;
					beam.mRaySamplePdf = raySamplePdf;
					beam.mRaySampleRevPdf = raySampleRevPdf;
					beam.mRaySamplingFlags = AbstractMedium::kEndInMedium;
					if (it == mVolumeSegments.cbegin())
						beam.mRaySamplingFlags |= aRaySamplingFlags;
					beam.mLastPdfWInv = aLastPdfWInv;
					beam.mThroughputAtOrigin = throughput;
					beam.mLightVertex = aLightVertex;
					
					UPBP_ASSERT(mPhotonBeamsArray.size() < mPhotonBeamsArray.capacity());
					mPhotonBeamsArray.push_back(beam);
				}
				throughput *= it->mAttenuation / it->mRaySamplePdf;
				raySamplePdf *= it->mRaySamplePdf;
				raySampleRevPdf *= it->mRaySampleRevPdf;
			}
		}
		else // LONG_BEAM
		{
			UPBP_ASSERT(mPhotonBeamType == LONG_BEAM);
			for (LiteVolumeSegments::const_iterator it = mLiteVolumeSegments.cbegin(); it != mLiteVolumeSegments.cend(); ++it)
			{
				UPBP_ASSERT(it->mMediumID >= 0);
				PhotonBeam beam;
				beam.mMedium = mScene.mMedia[it->mMediumID];
				if (beam.mMedium->HasScattering() && (!mMergeWithLightVerticesPB2D || beam.mMedium->GetMeanFreePath(aRay.origin) > mBB1DMinMFP))
				{
					beam.mRay = Ray(aRay.origin + aRay.direction * it->mDistMin, aRay.direction);
					beam.mLength = it->mDistMax - it->mDistMin;
					beam.mFlags = LONG_BEAM;
					beam.mRaySamplePdf = raySamplePdf;
					beam.mRaySampleRevPdf = raySampleRevPdf;
					beam.mRaySamplingFlags = AbstractMedium::kEndInMedium;
					if (it == mLiteVolumeSegments.cbegin())
						beam.mRaySamplingFlags |= aRaySamplingFlags;
					beam.mLastPdfWInv = aLastPdfWInv;
					beam.mThroughputAtOrigin = throughput;
					beam.mLightVertex = aLightVertex;

					UPBP_ASSERT(mPhotonBeamsArray.size() < mPhotonBeamsArray.capacity());
					mPhotonBeamsArray.push_back(beam);
				}
				if (beam.mMedium->IsHomogeneous())
				{
					const HomogeneousMedium * medium = ((const HomogeneousMedium *)beam.mMedium);
					throughput *= medium->EvalAttenuation(it->mDistMax - it->mDistMin);
				}
				else
				{
					throughput *= beam.mMedium->EvalAttenuation(aRay, it->mDistMin, it->mDistMax);
				}
				float segmentRaySampleRevPdf;
				float segmentRaySamplePdf = beam.mMedium->RaySamplePdf(aRay, it->mDistMin, it->mDistMax, it == mLiteVolumeSegments.cbegin() ? aRaySamplingFlags : 0, &segmentRaySampleRevPdf);
				raySamplePdf *= segmentRaySamplePdf;
				raySampleRevPdf *= segmentRaySampleRevPdf;
			}

			if (!mPhotonBeamsArray.empty() && mPhotonBeamsArray.back().mLength > mPhotonBeamsArray.back().mMedium->MaxBeamLength())
				mPhotonBeamsArray.back().mLength = mPhotonBeamsArray.back().mMedium->MaxBeamLength();
		}
	}

	// Accumulates PDF ratios of all sampling techniques along path originally sampled from light
	inline float AccumulateLightPathWeight2(
		const int   aPathIndex,
		const int   aPathLength,
		const float aLastRevPdfA,
		const float aLastSinTheta,
		const float aLastRaySampleRevPdfInv,
		const float aLastRaySampleRevPdfsRatio,
		const float aNextToLastPartialRevPdfW,
		const uint  aCurrentlyEvaluatedTechnique,
		const bool  aCameraConnection) const
	{
		return AccumulateLightPathWeight(aPathIndex, aPathLength, aLastRevPdfA, aLastSinTheta, aLastRaySampleRevPdfInv, aLastRaySampleRevPdfsRatio, aNextToLastPartialRevPdfW, aCurrentlyEvaluatedTechnique, mQueryBeamType, mPhotonBeamType, mEstimatorTechniques, aCameraConnection, &mPathEnds, &mLightVertices);
	}

	//////////////////////////////////////////////////////////////////////////
	// Common methods
	//////////////////////////////////////////////////////////////////////////
	
	// MIS power, we use balance heuristic
    float Mis(float aPdf) const
    {
        //return std::pow(aPdf, /*power*/);
        return aPdf;
    }

	// MIS weight for 2 PDFs
    float Mis2(
        float aSamplePdf,
        float aOtherPdf) const
    {
        return Mis(aSamplePdf) / (Mis(aSamplePdf) + Mis(aOtherPdf));
    }

	// Samples a scattering direction camera/light sample according to BSDF.
	// Returns false for termination
	bool SampleScattering(
		const BSDF    &aBSDF,
		const Pos     &aHitPoint,
		const Isect   &aIsect,
		SubPathState  &aoState,
		MisData       &aoCurrentMisData,
		MisData       &aoPreviousMisData)
	{
		// Sample scattering function		

		Dir   rndTriplet = mRng.GetVec3f(); // x,y for direction, z for component. No rescaling happens
		float bsdfDirPdfW, cosThetaOut, sinTheta;
		uint  sampledEvent;

		Rgb bsdfFactor = aBSDF.Sample(rndTriplet, aoState.mDirection,
			bsdfDirPdfW, cosThetaOut, &sampledEvent, &sinTheta);

		if (bsdfFactor.isBlackOrNegative())
			return false;

		bool specular = (sampledEvent & BSDF::kSpecular) != 0;

		// If we sampled specular event, then the reverse probability
		// cannot be evaluated, but we know it is exactly the same as
		// forward probability, so just set it. If non-specular event happened,
		// we evaluate the PDF
		float bsdfRevPdfW = bsdfDirPdfW;
		if (!specular)
			bsdfRevPdfW = aBSDF.Pdf(aoState.mDirection, BSDF::kReverse);

		//UPBP_ASSERT(bsdfDirPdfW);
		//UPBP_ASSERT(bsdfRevPdfW);

		// Russian roulette
		const float contProb = aBSDF.ContinuationProb();
		if (contProb == 0 || (contProb < 1.0f && mRng.GetFloat() > contProb))
			return false;

		bsdfDirPdfW *= contProb;
		bsdfRevPdfW *= contProb;

		const float bsdfDirPdfWInv = 1.0f / bsdfDirPdfW;

		// Update path state

		aoState.mOrigin = aHitPoint;
		aoState.mThroughput *= bsdfFactor * (cosThetaOut * bsdfDirPdfWInv);
		aoState.mSpecularPath &= specular ? 1 : 0;
		aoState.mLastPdfWInv = bsdfDirPdfWInv;
		aoState.mLastSpecular = specular;

		// Switch medium on refraction
		if ((sampledEvent & BSDF::kRefract) != 0)
			mScene.UpdateBoundaryStackOnRefract(aIsect, aoState.mBoundaryStack);

		// Update affected MIS data
		aoCurrentMisData.mRevPdfA *= cosThetaOut;
		aoCurrentMisData.mRevPdfAWithoutBsdf = aoCurrentMisData.mRevPdfA;
		aoCurrentMisData.mIsSpecular = specular;
		aoCurrentMisData.mSinTheta = aBSDF.IsInMedium() ? sinTheta : 0.0f;
		aoCurrentMisData.mCosThetaOut = cosThetaOut;
		aoPreviousMisData.mRevPdfA *= bsdfRevPdfW;

		return true;
	}

private:

	// Flags controlling computation according to the selected algorithm type
	bool mTraceLightPaths;
	bool mTraceCameraPaths;
	bool mConnectToCamera;
	bool mConnectToCameraFromSurf;
	bool mConnectToLightSource;
	bool mConnectToLightVertices;
	bool mMergeWithLightVerticesSurf;
	bool mMergeWithLightVerticesPP3D;
	bool mMergeWithLightVerticesPB2D;
	bool mMergeWithLightVerticesBB1D;
	
	// Flags of used estimator techniques (used when calling methods from outside)
	uint mEstimatorTechniques;

	// SURF
	float    mSurfMisWeightFactor; // Weight factor of SURF
	float    mSurfNormalization;   // 1 / (Pi * surf_radius^2 * light_path_count)
	HashGrid mSurfHashGrid;        // Hashgrid used for photon lookup
	float    mSurfRadiusInitial;   // Initial merging radius
	float    mSurfRadiusAlpha;     // Radius reduction rate parameter

	// PP3D	
	float    mPP3DMisWeightFactor;  // Weight factor of PP3D
	float    mPP3DNormalization;    // 1 / (4/3 * Pi * pp3d_radius^3 * light_path_count)
	HashGrid mPP3DHashGrid;         // Hashgrid used for photon lookup
	float    mPP3DRadiusInitial;    // Initial merging radius
	float    mPP3DRadiusAlpha;      // Radius reduction rate parameter

	// PB2D
	float             mPB2DMisWeightFactor;   // Weight factor of PB2D
	float             mPB2DNormalization;     // 1 / light_path_count	
	EmbreeBre         mPB2DEmbreeBre;         // Encapsulates storing photons and evaluating contributions of their intersections with beams
	float             mPB2DRadiusInitial;     // Initial merging radius
	float             mPB2DRadiusAlpha;       // Radius reduction rate parameter
	RadiusCalculation mPB2DRadiusCalculation; // Type of photon radius calculation	
	int	              mPB2DRadiusKNN;	      // Value x means that x-th closest photon will be used for calculation of radius of the current photon
	BeamType          mQueryBeamType;         // Short/long beam

	// BB1D
	float                mBB1DMisWeightFactor;       // Weight factor of BB1D
	float                mBB1DNormalization;         // 1 / bb1d_light_path_count
	PhotonBeamsEvaluator mBB1DPhotonBeams;           // Encapsulates evaluating contributions of their intersections with beams
	float                mBB1DRadiusInitial;         // Initial merging radius
	float                mBB1DRadiusAlpha;           // Radius reduction rate parameter
	RadiusCalculation    mBB1DRadiusCalculation;     // Type of photon radius calculation
	int	                 mBB1DRadiusKNN;             // Value x means that x-th closest beam vertex will be used for calculation of cone radius at the current beam vertex
	float                mBB1DMinMFP;                // Minimum MFP of medium to store photon beams in it
	BeamType             mPhotonBeamType;            // Short/long beam
	float                mBB1DUsedLightSubPathCount; // First mBB1DUsedLightSubPathCount out of mLightSubPathCount light paths will generate photon beams
	float                mBB1DBeamStorageFactor;     // Factor used for computation of minimum MFP of media where photon beams are used. The lower it is the denser media will use photon beams.
	
	float mScreenPixelCount;         // Number of pixels
	float mLightSubPathCount;        // Number of light sub-paths
	float mRefPathCountPerIter;      // Reference number of paths per iteration
	float mPathCountPerIter;         // Number of paths per iteration

	size_t mLightVerticesOnSurfaceCount; // Number of light vertices located on surface
	size_t mLightVerticesInMediumCount;  // Number of light vertices located in medium

	std::vector<UPBPLightVertex> mLightVertices;          // Stored light vertices
	MisData mCameraVerticesMisData[UPBP_CAMERA_MAXVERTS]; // Stored MIS data for camera vertices (we don't need store whole vertices as for light paths)
	PhotonBeamsArray mPhotonBeamsArray;	                  // Stored photon beams

	VolumeSegments mVolumeSegments;         // Path segments intersecting media (up to scattering point)
	LiteVolumeSegments mLiteVolumeSegments; // Lite path segments intersecting media (up to intersection with solid surface)

	// For light path belonging to pixel index [x] it stores
	// where it's light vertices end (begin is at [x-1])
	std::vector<int> mPathEnds;	

	// Used algorithm
	AlgorithmType mAlgorithm;

	// Random number generator
	Rng mRng;

	// Minimum distance from camera at which scattering events in media can occur
	float mMinDistToMed;

	int mBaseSeed;

	// Whether to ignore fully specular paths from camera
	bool mIgnoreFullySpecPaths;

	// Whether to print information about progress
	bool mVerbose;

	// Maximum memory for light vertices in thread
	size_t mMaxMemoryPerThread;

	Timer mTimer;
};

#endif //__UPBP_HXX__